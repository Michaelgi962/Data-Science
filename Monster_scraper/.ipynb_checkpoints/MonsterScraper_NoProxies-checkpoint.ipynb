{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Refactor Code For Scraping Monster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd # For Data Storage\n",
    "import requests # For website connection\n",
    "from bs4 import BeautifulSoup # For HTML parsing\n",
    "import time # For sleep \n",
    "import re # Regular expressions for removing non-ascii terms\n",
    "from itertools import groupby # For removing duplicates from lists\n",
    "import math # Need ceiling expression\n",
    "from nltk.corpus import stopwords # For filtering out words like 'is', 'the', 'of'\n",
    "stop_words = set(stopwords.words(\"english\")) #initialize stopwords    \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initialize Empty Lists For Dictionary "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Initialize Empty State Set\n",
    "state = []\n",
    "job_title = []\n",
    "\n",
    "#Initialize Empty Skills List\n",
    "r = []\n",
    "python = []\n",
    "java = []\n",
    "cpp = []\n",
    "ruby = []\n",
    "perl = []\n",
    "matlab = []\n",
    "javascript = []\n",
    "scala = []\n",
    "excel = []\n",
    "vba = []\n",
    "tableau = []\n",
    "d3 = []\n",
    "hadoop = []\n",
    "mapreduce = []\n",
    "spark = []\n",
    "pig = []\n",
    "hive = []\n",
    "shark = []\n",
    "oozie = []\n",
    "zookeeper = []\n",
    "flume = []\n",
    "mahout = []\n",
    "sql = [] \n",
    "mysql = []\n",
    "oracle = []\n",
    "postgresql = []\n",
    "nosql =[]\n",
    "sybase = []\n",
    "rethinkdb = []\n",
    "memcacheddb = []\n",
    "couchdb = []\n",
    "hbase = []\n",
    "cassandra = []\n",
    "mongodb = []\n",
    "db2 = []\n",
    "\n",
    "skills = ['r',\n",
    "'python',\n",
    "'java',\n",
    "'c++',\n",
    "'ruby',\n",
    "'perl',\n",
    "'matlab',\n",
    "'javascript',\n",
    "'scala', \n",
    "'excel',\n",
    "'vba',\n",
    "'tableau',\n",
    "'d3',\n",
    "'hadoop',\n",
    "'mapreduce',\n",
    "'spark',\n",
    "'pig',\n",
    "'hive',\n",
    "'shark',\n",
    "'oozie',\n",
    "'zookeeper',\n",
    "'flume',\n",
    "'mahout',\n",
    "'sql', \n",
    "'mysql',\n",
    "'oracle',\n",
    "'postgresql',\n",
    "'nosql',\n",
    "'sybase',\n",
    "'rethinkdb',\n",
    "'memcacheddb',\n",
    "'couchdb',\n",
    "'hbase',\n",
    "'cassandra',\n",
    "'mongodb',\n",
    "'db2'\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialize the Dictionary "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "dictionary = {'job_title':job_title,\n",
    "     'state':state,\n",
    "     'r':r,\n",
    "     'python':python,\n",
    "     'java':java,\n",
    "     'c++':cpp,\n",
    "     'ruby':ruby,\n",
    "     'perl':perl,\n",
    "     'matlab':matlab,\n",
    "     'javascript':javascript,\n",
    "     'scala':scala,\n",
    "     'excel':excel,\n",
    "     'vba':vba,\n",
    "     'tableau':tableau,\n",
    "     'd3':d3,\n",
    "     'hadoop':hadoop,\n",
    "     'mapreduce':mapreduce,\n",
    "     'spark':spark,\n",
    "     'pig':pig,\n",
    "     'hive':hive,\n",
    "     'shark':shark,\n",
    "     'oozie':oozie,\n",
    "     'zookeeper':zookeeper,\n",
    "     'flume':flume,\n",
    "     'mahout':mahout,\n",
    "     'sql':sql, \n",
    "     'mysql':mysql,\n",
    "     'oracle':oracle,\n",
    "     'postgresql':postgresql,\n",
    "     'nosql':nosql,\n",
    "     'sybase':sybase,\n",
    "     'rethinkdb':rethinkdb,\n",
    "     'memcacheddb':memcacheddb,\n",
    "     'couchdb':couchdb,\n",
    "     'hbase':hbase,\n",
    "     'cassandra':cassandra,\n",
    "     'mongodb':mongodb,\n",
    "     'db2':db2}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def addValsToDict(url_state,url_job_title):\n",
    "    #Append state\n",
    "    state.append(url_state)\n",
    "\n",
    "    #Append job_title\n",
    "    job_title.append(url_job_title)\n",
    "\n",
    "    #Check if the each skill is in the wrangled text\n",
    "    for skill in skills:\n",
    "        if (skill in text_final) == True:\n",
    "            dictionary[skill].append(1)\n",
    "        else:\n",
    "            dictionary[skill].append(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clearDict():\n",
    "    for key in dictionary:\n",
    "        dictionary[key] = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get a URL for a Job Search for a chosen State"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "url_state = 'NY'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Store the job search in a beautiful soup object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://www.monster.com/jobs/search/?q=data-scientist&where='+url_state+'&stpage=1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Access the website\n",
    "response = requests.get(url)\n",
    "##print(response)  #Response 200 means the get request was a success\n",
    "soup = BeautifulSoup(response.text, \"html.parser\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get the url for up to 250 job posts in each state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "states = [\"AL\", \"AK\", \"AZ\", \"AR\", \"CA\", \"CO\", \"CT\", \"DE\", \"FL\", \"GA\", \n",
    "          \"HI\", \"ID\", \"IL\", \"IN\", \"IA\", \"KS\", \"KY\", \"LA\", \"ME\", \"MD\", \n",
    "          \"MA\", \"MI\", \"MN\", \"MS\", \"MO\", \"MT\", \"NE\", \"NV\", \"NH\", \"NJ\", \n",
    "          \"NM\", \"NY\", \"NC\", \"ND\", \"OH\", \"OK\", \"OR\", \"PA\", \"RI\", \"SC\", \n",
    "          \"SD\", \"TN\", \"TX\", \"UT\", \"VT\", \"VA\", \"WA\", \"WV\", \"WI\", \"WY\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize Empty URL Dictionary\n",
    "final_state_url_dict = {}\n",
    "\n",
    "for url_state in states:\n",
    "    url = 'https://www.monster.com/jobs/search/?q=data-scientist&where='+url_state+'&stpage=1'\n",
    "    response = requests.get(url) #Get the html code\n",
    "    soup = BeautifulSoup(response.text, \"html.parser\") #Store html in a soup object \n",
    "\n",
    "    #Get the total number of listed jobs \n",
    "    totalJobOpenings = float(re.sub('[^0-9]','',soup.html.body.find_all('h2')[0].text.strip()))\n",
    "    \n",
    "    #Get the total number of pages (up to 10)\n",
    "    totalPages = min(math.ceil(totalJobOpenings/25),10)\n",
    "    \n",
    "    #Store the Final URL in a dictionary each state\n",
    "    final_state_url_dict[url_state] = 'https://www.monster.com/jobs/search/?q=data-scientist&where='+url_state+'&stpage=1&page='+str(totalPages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'AL': 'https://www.monster.com/jobs/search/?q=data-scientist&where=AL&stpage=1&page=7',\n",
       " 'AK': 'https://www.monster.com/jobs/search/?q=data-scientist&where=AK&stpage=1&page=1',\n",
       " 'AZ': 'https://www.monster.com/jobs/search/?q=data-scientist&where=AZ&stpage=1&page=10',\n",
       " 'AR': 'https://www.monster.com/jobs/search/?q=data-scientist&where=AR&stpage=1&page=3',\n",
       " 'CA': 'https://www.monster.com/jobs/search/?q=data-scientist&where=CA&stpage=1&page=10',\n",
       " 'CO': 'https://www.monster.com/jobs/search/?q=data-scientist&where=CO&stpage=1&page=10',\n",
       " 'CT': 'https://www.monster.com/jobs/search/?q=data-scientist&where=CT&stpage=1&page=10',\n",
       " 'DE': 'https://www.monster.com/jobs/search/?q=data-scientist&where=DE&stpage=1&page=4',\n",
       " 'FL': 'https://www.monster.com/jobs/search/?q=data-scientist&where=FL&stpage=1&page=10',\n",
       " 'GA': 'https://www.monster.com/jobs/search/?q=data-scientist&where=GA&stpage=1&page=10',\n",
       " 'HI': 'https://www.monster.com/jobs/search/?q=data-scientist&where=HI&stpage=1&page=2',\n",
       " 'ID': 'https://www.monster.com/jobs/search/?q=data-scientist&where=ID&stpage=1&page=3',\n",
       " 'IL': 'https://www.monster.com/jobs/search/?q=data-scientist&where=IL&stpage=1&page=10',\n",
       " 'IN': 'https://www.monster.com/jobs/search/?q=data-scientist&where=IN&stpage=1&page=6',\n",
       " 'IA': 'https://www.monster.com/jobs/search/?q=data-scientist&where=IA&stpage=1&page=5',\n",
       " 'KS': 'https://www.monster.com/jobs/search/?q=data-scientist&where=KS&stpage=1&page=4',\n",
       " 'KY': 'https://www.monster.com/jobs/search/?q=data-scientist&where=KY&stpage=1&page=3',\n",
       " 'LA': 'https://www.monster.com/jobs/search/?q=data-scientist&where=LA&stpage=1&page=3',\n",
       " 'ME': 'https://www.monster.com/jobs/search/?q=data-scientist&where=ME&stpage=1&page=2',\n",
       " 'MD': 'https://www.monster.com/jobs/search/?q=data-scientist&where=MD&stpage=1&page=10',\n",
       " 'MA': 'https://www.monster.com/jobs/search/?q=data-scientist&where=MA&stpage=1&page=10',\n",
       " 'MI': 'https://www.monster.com/jobs/search/?q=data-scientist&where=MI&stpage=1&page=10',\n",
       " 'MN': 'https://www.monster.com/jobs/search/?q=data-scientist&where=MN&stpage=1&page=9',\n",
       " 'MS': 'https://www.monster.com/jobs/search/?q=data-scientist&where=MS&stpage=1&page=3',\n",
       " 'MO': 'https://www.monster.com/jobs/search/?q=data-scientist&where=MO&stpage=1&page=10',\n",
       " 'MT': 'https://www.monster.com/jobs/search/?q=data-scientist&where=MT&stpage=1&page=1',\n",
       " 'NE': 'https://www.monster.com/jobs/search/?q=data-scientist&where=NE&stpage=1&page=3',\n",
       " 'NV': 'https://www.monster.com/jobs/search/?q=data-scientist&where=NV&stpage=1&page=3',\n",
       " 'NH': 'https://www.monster.com/jobs/search/?q=data-scientist&where=NH&stpage=1&page=1',\n",
       " 'NJ': 'https://www.monster.com/jobs/search/?q=data-scientist&where=NJ&stpage=1&page=10',\n",
       " 'NM': 'https://www.monster.com/jobs/search/?q=data-scientist&where=NM&stpage=1&page=4',\n",
       " 'NY': 'https://www.monster.com/jobs/search/?q=data-scientist&where=NY&stpage=1&page=10',\n",
       " 'NC': 'https://www.monster.com/jobs/search/?q=data-scientist&where=NC&stpage=1&page=10',\n",
       " 'ND': 'https://www.monster.com/jobs/search/?q=data-scientist&where=ND&stpage=1&page=2',\n",
       " 'OH': 'https://www.monster.com/jobs/search/?q=data-scientist&where=OH&stpage=1&page=10',\n",
       " 'OK': 'https://www.monster.com/jobs/search/?q=data-scientist&where=OK&stpage=1&page=4',\n",
       " 'OR': 'https://www.monster.com/jobs/search/?q=data-scientist&where=OR&stpage=1&page=10',\n",
       " 'PA': 'https://www.monster.com/jobs/search/?q=data-scientist&where=PA&stpage=1&page=10',\n",
       " 'RI': 'https://www.monster.com/jobs/search/?q=data-scientist&where=RI&stpage=1&page=2',\n",
       " 'SC': 'https://www.monster.com/jobs/search/?q=data-scientist&where=SC&stpage=1&page=7',\n",
       " 'SD': 'https://www.monster.com/jobs/search/?q=data-scientist&where=SD&stpage=1&page=2',\n",
       " 'TN': 'https://www.monster.com/jobs/search/?q=data-scientist&where=TN&stpage=1&page=10',\n",
       " 'TX': 'https://www.monster.com/jobs/search/?q=data-scientist&where=TX&stpage=1&page=10',\n",
       " 'UT': 'https://www.monster.com/jobs/search/?q=data-scientist&where=UT&stpage=1&page=10',\n",
       " 'VT': 'https://www.monster.com/jobs/search/?q=data-scientist&where=VT&stpage=1&page=1',\n",
       " 'VA': 'https://www.monster.com/jobs/search/?q=data-scientist&where=VA&stpage=1&page=10',\n",
       " 'WA': 'https://www.monster.com/jobs/search/?q=data-scientist&where=WA&stpage=1&page=10',\n",
       " 'WV': 'https://www.monster.com/jobs/search/?q=data-scientist&where=WV&stpage=1&page=1',\n",
       " 'WI': 'https://www.monster.com/jobs/search/?q=data-scientist&where=WI&stpage=1&page=6',\n",
       " 'WY': 'https://www.monster.com/jobs/search/?q=data-scientist&where=WY&stpage=1&page=2'}"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_state_url_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Access every URL with the find_all function\n",
    "##print(soup.find_all('a'))\n",
    "links = []\n",
    "#Access every URL within the list of returned urls from findall\n",
    "for link in soup.find_all('a'):\n",
    "    if link.get('href')[0:21] == 'https://job-openings.': ## a job opening always begins with 'https://job-openings.monster.com'\n",
    "        links.append(link.get('href'))        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Get job post URLs on first page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Access every URL with the find_all function\n",
    "##print(soup.find_all('a'))\n",
    "links = []\n",
    "#Access every URL within the list of returned urls from findall\n",
    "for link in soup.find_all('a'):\n",
    "    if link.get('href')[0:21] == 'https://job-openings.': ## a job opening always begins with 'https://job-openings.monster.com'\n",
    "        links.append(link.get('href'))        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "250"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(links)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get the total number of listed jobs \n",
    "totalJobOpenings = float(re.sub('[^0-9]','',soup.html.body.find_all('h2')[0].text.strip()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# there will be a page for every 25 urls \n",
    "# for 1473 pages there are int(1473/25) pages\n",
    "num_pages = str(min(10,int(totalJobOpenings/25)))\n",
    "# Make a URL for up to the first 250 links\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get ALL job url posts from the state (up to the first 250)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://www.monster.com/jobs/search/?q=data-scientist&where='+url_state+'&stpage=1&page='+num_pages"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Get job post URLs on first page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Access every URL with the find_all function\n",
    "##print(soup.find_all('a'))\n",
    "links = []\n",
    "#Access every URL within the list of returned urls from findall\n",
    "for link in soup.find_all('a'):\n",
    "    if link.get('href')[0:21] == 'https://job-openings.': ## a job opening always begins with 'https://job-openings.monster.com'\n",
    "        links.append(link.get('href'))        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_job_openings = len(links)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of job openings in NY are (at least): 250\n"
     ]
    }
   ],
   "source": [
    "print( 'The number of job openings in {} are (at least): {}'.format(url_state,num_job_openings))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Check Each Link in State"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "count = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n",
      "32\n",
      "33\n",
      "34\n",
      "35\n",
      "36\n",
      "37\n",
      "38\n",
      "39\n",
      "40\n",
      "41\n",
      "42\n",
      "43\n",
      "44\n",
      "45\n",
      "46\n",
      "47\n",
      "48\n",
      "49\n",
      "50\n",
      "51\n",
      "52\n",
      "53\n",
      "54\n",
      "55\n",
      "56\n",
      "57\n",
      "58\n",
      "59\n",
      "60\n",
      "61\n",
      "62\n",
      "63\n",
      "64\n",
      "65\n",
      "66\n",
      "67\n",
      "68\n",
      "69\n",
      "70\n",
      "71\n",
      "72\n",
      "73\n",
      "74\n",
      "75\n",
      "76\n",
      "77\n",
      "78\n",
      "79\n",
      "80\n",
      "81\n",
      "82\n",
      "83\n",
      "84\n",
      "85\n",
      "86\n",
      "87\n",
      "88\n",
      "89\n",
      "90\n",
      "91\n",
      "92\n",
      "93\n",
      "94\n",
      "95\n",
      "96\n",
      "97\n",
      "98\n",
      "99\n",
      "100\n",
      "101\n",
      "102\n",
      "103\n",
      "104\n",
      "105\n",
      "106\n",
      "107\n",
      "108\n",
      "109\n",
      "110\n",
      "111\n",
      "112\n",
      "113\n",
      "114\n",
      "115\n",
      "116\n",
      "117\n",
      "118\n",
      "119\n",
      "120\n",
      "121\n",
      "122\n",
      "123\n",
      "124\n",
      "125\n",
      "126\n",
      "127\n",
      "128\n",
      "129\n",
      "130\n",
      "131\n",
      "132\n",
      "133\n",
      "134\n",
      "135\n",
      "136\n",
      "137\n",
      "138\n",
      "139\n",
      "140\n",
      "141\n",
      "142\n",
      "143\n",
      "144\n",
      "145\n",
      "146\n",
      "147\n",
      "148\n",
      "149\n",
      "150\n",
      "151\n",
      "152\n",
      "153\n",
      "154\n",
      "155\n",
      "156\n",
      "157\n",
      "158\n",
      "159\n",
      "160\n",
      "161\n",
      "162\n",
      "163\n",
      "164\n",
      "165\n",
      "166\n",
      "167\n",
      "168\n",
      "169\n",
      "170\n",
      "171\n",
      "172\n",
      "173\n",
      "174\n",
      "175\n",
      "176\n",
      "177\n",
      "178\n",
      "179\n",
      "180\n",
      "181\n",
      "182\n",
      "183\n",
      "184\n",
      "185\n",
      "186\n",
      "187\n",
      "188\n",
      "189\n",
      "190\n",
      "191\n",
      "192\n",
      "193\n",
      "194\n",
      "195\n",
      "196\n",
      "197\n",
      "198\n",
      "199\n",
      "200\n",
      "201\n",
      "202\n",
      "203\n",
      "204\n",
      "205\n",
      "206\n",
      "207\n",
      "208\n",
      "209\n",
      "210\n",
      "211\n",
      "212\n",
      "213\n",
      "214\n",
      "215\n",
      "216\n",
      "217\n",
      "218\n",
      "219\n",
      "220\n",
      "221\n",
      "222\n",
      "223\n",
      "224\n",
      "225\n",
      "226\n",
      "227\n",
      "228\n",
      "229\n",
      "230\n",
      "231\n",
      "232\n",
      "233\n",
      "234\n",
      "235\n",
      "236\n",
      "237\n",
      "238\n",
      "239\n",
      "240\n",
      "241\n",
      "242\n",
      "243\n",
      "244\n",
      "245\n",
      "246\n",
      "247\n",
      "248\n",
      "249\n",
      "250\n"
     ]
    }
   ],
   "source": [
    "for job_opening_url in links:\n",
    "    count += 1\n",
    "    print(count)\n",
    "    # sleep for .01 btw requests to not simulate ddos attack or w/e\n",
    "    time.sleep(.01)\n",
    "    \n",
    "    #Access the website\n",
    "    response = requests.get(job_opening_url)\n",
    "    \n",
    "    #Get the html soup!\n",
    "    soup = BeautifulSoup(response.text, \"html.parser\")\n",
    "    \n",
    "    #Get the job title from the html soup\n",
    "    url_job_title = soup.title.string[0:-14] # the last 14 characters are  '| Monster.com'\n",
    "    \n",
    "    #Get and clean the text from the job posting\n",
    "    text = soup.body.find_all('script')[1]\n",
    "\n",
    "    # Convert to string -> Convert to lower case \n",
    "    ## -> replace (all non ascii characters, ., and 3) with ','\n",
    "    ### -> split string into a list separated by ','-> remove all consecutive duplicates \n",
    "\n",
    "    text_newest = [x[0] for x in groupby([x[0] for x in groupby(re.sub(\"[^a-zA-Z.+3]\",',',str(text).lower()).split(','))])]\n",
    "\n",
    "    #Remove the stopwords and empty spaces\n",
    "    text_final = [x for x in text_newest if not x in stop_words and not x =='']\n",
    "    \n",
    "    #Add the values to the Dictionary\n",
    "    addValsToDict(url_state,url_job_title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "250\n",
      "250\n",
      "250\n",
      "250\n",
      "250\n",
      "250\n",
      "250\n",
      "250\n",
      "250\n",
      "250\n",
      "250\n",
      "250\n",
      "250\n",
      "250\n",
      "250\n",
      "250\n",
      "250\n",
      "250\n",
      "250\n",
      "250\n",
      "250\n",
      "250\n",
      "250\n",
      "250\n",
      "250\n",
      "250\n",
      "250\n",
      "250\n",
      "250\n",
      "250\n",
      "250\n",
      "250\n",
      "250\n",
      "250\n",
      "250\n",
      "250\n",
      "250\n",
      "250\n"
     ]
    }
   ],
   "source": [
    "for x in dictionary:\n",
    "    print(len(dictionary[x]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for x in dictionary:\n",
    "#    print(len(dictionary[str(x)]))\n",
    "data = pd.DataFrame(dictionary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>job_title</th>\n",
       "      <th>state</th>\n",
       "      <th>r</th>\n",
       "      <th>python</th>\n",
       "      <th>java</th>\n",
       "      <th>c++</th>\n",
       "      <th>ruby</th>\n",
       "      <th>perl</th>\n",
       "      <th>matlab</th>\n",
       "      <th>javascript</th>\n",
       "      <th>...</th>\n",
       "      <th>postgresql</th>\n",
       "      <th>nosql</th>\n",
       "      <th>sybase</th>\n",
       "      <th>rethinkdb</th>\n",
       "      <th>memcacheddb</th>\n",
       "      <th>couchdb</th>\n",
       "      <th>hbase</th>\n",
       "      <th>cassandra</th>\n",
       "      <th>mongodb</th>\n",
       "      <th>db2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Data Scientist job at comScore, Inc.</td>\n",
       "      <td>NY</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Data Scientist - Predictive Modeling job at Re...</td>\n",
       "      <td>NY</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Data Scientist job at Xsell Resources</td>\n",
       "      <td>NY</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Client-Facing Applied Data Scientist job at Cy...</td>\n",
       "      <td>NY</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Senior Data Scientist, Analytics Lab Team job ...</td>\n",
       "      <td>NY</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Data Scientist job at Interactive Brokers LLC</td>\n",
       "      <td>NY</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Senior Data Scientist job at Brainworks</td>\n",
       "      <td>NY</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Data Scientist job at Crestron Electronics</td>\n",
       "      <td>NY</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Data Scientist / Python Engineer job at DEEGIT...</td>\n",
       "      <td>NY</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Data Scientist (only Full-time) job at Brezo B...</td>\n",
       "      <td>NY</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 38 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           job_title state  r  python  java  \\\n",
       "0               Data Scientist job at comScore, Inc.    NY  1       1     0   \n",
       "1  Data Scientist - Predictive Modeling job at Re...    NY  1       0     0   \n",
       "2              Data Scientist job at Xsell Resources    NY  1       1     1   \n",
       "3  Client-Facing Applied Data Scientist job at Cy...    NY  0       1     0   \n",
       "4  Senior Data Scientist, Analytics Lab Team job ...    NY  1       1     1   \n",
       "5      Data Scientist job at Interactive Brokers LLC    NY  0       0     0   \n",
       "6            Senior Data Scientist job at Brainworks    NY  1       1     0   \n",
       "7         Data Scientist job at Crestron Electronics    NY  1       1     0   \n",
       "8  Data Scientist / Python Engineer job at DEEGIT...    NY  0       1     0   \n",
       "9  Data Scientist (only Full-time) job at Brezo B...    NY  0       1     1   \n",
       "\n",
       "   c++  ruby  perl  matlab  javascript ...   postgresql  nosql  sybase  \\\n",
       "0    0     0     0       0           0 ...            0      0       0   \n",
       "1    0     0     0       0           0 ...            0      0       0   \n",
       "2    0     0     0       0           1 ...            0      0       0   \n",
       "3    0     0     0       1           0 ...            0      0       0   \n",
       "4    1     0     0       0           0 ...            0      1       0   \n",
       "5    0     0     0       0           0 ...            0      0       0   \n",
       "6    0     0     0       1           0 ...            0      0       0   \n",
       "7    0     0     0       0           0 ...            0      0       0   \n",
       "8    0     0     0       0           0 ...            0      1       0   \n",
       "9    1     1     0       0           0 ...            0      0       0   \n",
       "\n",
       "   rethinkdb  memcacheddb  couchdb  hbase  cassandra  mongodb  db2  \n",
       "0          0            0        0      0          0        0    0  \n",
       "1          0            0        0      0          0        0    0  \n",
       "2          0            0        0      0          0        0    0  \n",
       "3          0            0        0      0          0        0    0  \n",
       "4          0            0        0      0          1        1    0  \n",
       "5          0            0        0      0          0        0    0  \n",
       "6          0            0        0      0          0        0    0  \n",
       "7          0            0        0      0          0        0    0  \n",
       "8          0            0        0      0          0        0    0  \n",
       "9          0            0        0      0          0        0    0  \n",
       "\n",
       "[10 rows x 38 columns]"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "db2            0.000\n",
       "zookeeper      0.000\n",
       "oozie          0.000\n",
       "memcacheddb    0.000\n",
       "rethinkdb      0.000\n",
       "sybase         0.004\n",
       "mahout         0.004\n",
       "flume          0.004\n",
       "couchdb        0.004\n",
       "shark          0.004\n",
       "vba            0.008\n",
       "ruby           0.024\n",
       "postgresql     0.036\n",
       "mapreduce      0.044\n",
       "hbase          0.048\n",
       "javascript     0.048\n",
       "perl           0.048\n",
       "oracle         0.052\n",
       "mongodb        0.052\n",
       "mysql          0.052\n",
       "cassandra      0.056\n",
       "d3             0.056\n",
       "pig            0.064\n",
       "matlab         0.088\n",
       "c++            0.104\n",
       "nosql          0.124\n",
       "excel          0.128\n",
       "hive           0.140\n",
       "scala          0.164\n",
       "tableau        0.212\n",
       "java           0.248\n",
       "spark          0.284\n",
       "hadoop         0.296\n",
       "sql            0.504\n",
       "r              0.556\n",
       "python         0.660\n",
       "dtype: float64"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.mean().sort_values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
